<p align="center">
    <a href="https://www.python.org/dev/peps/"><img src="https://img.shields.io/badge/code_style-standard-brightgreen.svg" alt="Standard - Python Style Guide"></a>
    <a href="http://opensources.co"><img src="https://img.shields.io/badge/Data-OpenSources-blue.svg" alt="OpenSources Data"></a>
</p>

<center><img src='images/newsstand.jpg'></center>

    
# Capstone Project - News Content

Over the past two decades and especially since the United States presidential election 2016 there is an increase in unreliable news content. The question which got and still gets asked is how can we know which is which. To find an answer I started at [opensources](http://www.opensources.co/) which curates a list of online information sources. The websites listed range from credible news to misleading and outright fake.

__UPDATE__: The website for opensources.co doesn't exist anymore.

### Modivation

To help me approach the project right, I split the project into three different tasks (notebooks):

+ collecting content [(01_data_collection.ipynb)](01_data_collection.ipynb)
+ data exploration [(02_data_exploration.ipynb)](02_data_exploration.ipynb)
+ creating a keras model [(03_data_modeling.ipynb)](03_data_modeling.ipynb)

I am interested in trying to answer the following questions:

+ how much unreliable content can we find
+ what makes that content different
+ can we create deep learning models to help us differentiate

What are the next steps?

+ create a dashboard to copy/paste news content to make a prediction
+ add classifiers to distinguish the text better based on its "content" and "context".

## Blog Post(s)

The following blog posts describe the work flow of each notebook and it approach:

Part 1: [collecting news content for this project using different tools](https://data-ocean.github.io/text_classification_part_1/)

Part 2: [exploring our data to help us understand better what type of content we have](https://data-ocean.github.io/text_classification_part_2/)

Part 3: [building a deep learning model to predict whether a given text is reliable or not](https://data-ocean.github.io/text_classification_part_3/)

Part 4: next step(s)

---

License MIT Â© [Stephan Osterburg](https://stephanosterburg.github.io)
